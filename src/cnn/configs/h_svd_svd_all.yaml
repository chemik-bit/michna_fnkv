image_size:
  1: [220, 220]
  2: [230, 230]
  3: [240, 240]
  4: [250, 250]
  5: [210, 210]
  6: [200, 200]
balances: [False]
wav_chunks: [1]
octaves: []
fft_lens: [256]
fft_overlaps: [128]
training_db: svdadult
validation_db: svdadult
batch_size_exp: 4
max_epochs: 150
lr: 0.00001
transform: v1
models: ['src.cnn.models.h_cnn001.py',
 'src.cnn.models.h_cnn001_001.py',
 'src.cnn.models.h_cnn001_002.py',
 'src.cnn.models.h_cnn001_002_001.py',
 'src.cnn.models.h_cnn001_002_002.py',
 'src.cnn.models.h_cnn001_002_003.py',
 'src.cnn.models.h_cnn001_002_004.py',
 'src.cnn.models.h_cnn001_002_005.py',
 'src.cnn.models.h_cnn001_002_006.py',
 'src.cnn.models.h_cnn001_002_007.py',
 'src.cnn.models.h_cnn001_002_008.py',
 'src.cnn.models.h_cnn001_002_009.py',
 'src.cnn.models.h_cnn001_003.py',
 'src.cnn.models.h_cnn001_003_001.py',
 'src.cnn.models.h_cnn001_003_002.py',
 'src.cnn.models.h_cnn001_003_003.py',
 'src.cnn.models.h_cnn001_003_004.py',
 'src.cnn.models.h_cnn001_004.py',
 'src.cnn.models.h_cnn001_005.py',
 'src.cnn.models.h_cnn002.py',
 'src.cnn.models.h_cnn002_001.py',
 'src.cnn.models.h_cnn002_002.py',
 'src.cnn.models.h_cnn002_003.py',
 'src.cnn.models.h_cnn002_004.py',
 'src.cnn.models.h_cnn002_005.py',
 'src.cnn.models.h_cnn002_006.py',
 'src.cnn.models.h_cnn002_007.py',
 'src.cnn.models.h_cnn002_008.py',
 'src.cnn.models.h_cnn002_009.py',
 'src.cnn.models.h_cnn003.py',
 'src.cnn.models.h_cnn004.py',
 'src.cnn.models.k_cnn001_001.py',
 'src.cnn.models.k_cnn001_0013.py',
 'src.cnn.models.k_cnn001_0014.py',
 'src.cnn.models.k_cnn001_0015.py',
 'src.cnn.models.k_cnn001_002.py',
 'src.cnn.models.k_cnn001_003.py',
 'src.cnn.models.k_cnn001_004.py',
 'src.cnn.models.k_cnn001_005.py',
 'src.cnn.models.k_cnn001_006.py',
 'src.cnn.models.k_cnn001_007.py',
 'src.cnn.models.k_cnn001_008.py',
 'src.cnn.models.k_cnn001_009.py',
 'src.cnn.models.k_cnn001_010.py',
 'src.cnn.models.k_cnn001_011.py',
 'src.cnn.models.k_cnn001_012.py',
]
loss: focal_loss
optimizer: adam